{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11441270,"sourceType":"datasetVersion","datasetId":7167152}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Chargement du jeu de donnees pretraite depuis le  referentielle google drive**","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm  # Pour une barre de progression\n\n# 1. Fonction pour charger les images brutes\ndef load_raw_image(filepath):\n    filename = os.path.basename(filepath)  # Exemple: 'bruised_plum_0.png'\n    label = os.path.splitext(filename)[0].split('_')[0]  # Enlève l'extension => 'bruised'\n\n    # Charger l'image et la convertir en array numpy\n    img = Image.open(filepath).convert('RGB')\n    img_array = np.array(img)\n\n    return {'label': label, 'image': img_array}\n\n# 2. Parcourir le dossier et remplir le DataFrame\ndata = []\n# landry237_plum_dataset_split_path contains the downloaded data\ntrain_dir = '/kaggle/working/data/data_split/train' # Using the downloaded data path\n\nfor filename in tqdm(os.listdir(train_dir)):\n    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n        filepath = os.path.join(train_dir, filename)\n        data.append(load_raw_image(filepath))\n\n# 3. Créer le DataFrame\ndf = pd.DataFrame(data)\n\n# Aperçu des données\nprint(f\"Nombre d'images chargées : {len(df)}\")\nprint(df.head())\n\n# Exemple d'accès aux données\nprint(\"Shape d'une image :\", df.iloc[0]['image'].shape)  # (Hauteur, Largeur, Canaux)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U gdown  # au cas où gdown n'est pas installé\nimport os\n\nFILE_ID = \"1UxMCTBZiQGXIQShuEAdaSKn2Y_hKnDQj\"\n\n# Créer un dossier pour le zip\nos.makedirs(\"data\", exist_ok=True)\n\n# Télécharger le fichier zip depuis Google Drive\n!gdown {FILE_ID} -O data/dataset.zip\n\n# Décompresser le fichier zip\n!unzip -q data/dataset.zip -d data/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Chargement des donnees d'entrainement**","metadata":{}},{"cell_type":"markdown","source":"### **Chargement des donnees de teste**","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm  # Pour une barre de progression\n\n# 1. Fonction pour charger les images brutes\ndef load_raw_image(filepath):\n    filename = os.path.basename(filepath)  # Exemple: 'bruised_plum_0.png'\n    label = os.path.splitext(filename)[0].split('_')[0]  # Enlève l'extension => 'bruised'\n\n    # Charger l'image et la convertir en array numpy\n    img = Image.open(filepath).convert('RGB')\n    img_array = np.array(img)\n\n    return {'classes': label, 'image': img_array}\n\n# 2. Parcourir le dossier et remplir le DataFrame\ndata = []\ntest_dir = '/kaggle/working/data/data_split/test'  # Chemin à adapter si besoin\n\nfor filename in tqdm(os.listdir(test_dir)):\n    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n        filepath = os.path.join(test_dir, filename)\n        data.append(load_raw_image(filepath))\n\n# 3. Créer le DataFrame\ndf_test = pd.DataFrame(data)\n\n# Aperçu des données\nprint(f\"Nombre d'images chargées : {len(df_test)}\")\nprint(df_test.head())\n\n# Exemple d'accès aux données\nprint(\"Shape d'une image :\", df_test.iloc[0]['image'].shape)  # (Hauteur, Largeur, Canaux)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Fonction permettant d'afficher 'n' images prit aleatoirement**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\nimport math\n\ndef show_random_images(df, n=8):\n    \"\"\"\n    Affiche n images aléatoires du DataFrame avec 4 images maximum par ligne.\n    \"\"\"\n    n = min(n, len(df))  # Pour éviter un dépassement\n    indices = random.sample(range(len(df)), n)\n\n    # Calcul du nombre de lignes (4 images par ligne max)\n    cols = 4\n    rows = math.ceil(n / cols)\n\n    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n    axes = axes.flatten()  # Pour pouvoir itérer facilement\n\n    for i in range(rows * cols):\n        ax = axes[i]\n        if i < n:\n            img = df.iloc[indices[i]]['image']\n            label = df.iloc[indices[i]]['label']\n            ax.imshow(img)\n            ax.set_title(label, fontsize=10)\n        ax.axis('off')  # Cacher les axes même s'il n'y a pas d'image\n\n    plt.tight_layout()\n    plt.show()\n\nshow_random_images(df, n=12)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Ici on extrait du dataset les lignes appartenant a la categorie defective. c'est a dire les prunes defectueses**","metadata":{}},{"cell_type":"code","source":"# Liste des mots-clés représentant les défauts(defective)\ndefective_keywords = ['bruised', 'cracked', 'rotten', 'spotted']\n\n# Garder uniquement les lignes dont le label contient un mot-clé défectueux\ndf_defective = df[df['label'].apply(lambda x: any(keyword in x.lower() for keyword in defective_keywords))].reset_index(drop=True)\n\n# Affichage rapide\nprint(f\"Nombre d'images défectueuses : {len(df_defective)}\\n\\n\")\nprint(df_defective.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **On renomme le dataset en df_label. Pour dire dataset dont les classes sont les 03 labels**","metadata":{}},{"cell_type":"code","source":"df_label = df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Visualisation de 12 images de prunes defectueses**","metadata":{}},{"cell_type":"code","source":"show_random_images(df_defective, n=12)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Fonction permettant d'afficher la distribution de chaque classe dans le dataset passe en parametre**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_label_distribution(df, label_column='label'):\n    \"\"\"\n    Visualise la distribution des défauts avec un barplot horizontal professionnel\n    \n    Args:\n        df: DataFrame contenant les données\n        label_column: Colonne contenant les catégories de défauts\n    \"\"\"\n    # Configuration du style\n    sns.set_style(\"whitegrid\", {'axes.grid': False})\n    plt.figure(figsize=(10, 6))\n    \n    # Création du plot\n    ax = df[label_column].value_counts().plot(\n        kind='barh',\n        color=sns.color_palette(\"Dark2\"),\n        width=0.85,\n        edgecolor='black',\n        linewidth=0.5\n    )\n    \n    # Personnalisation avancée\n    ax.spines[['top', 'right', 'left']].set_visible(False)\n    ax.tick_params(axis='y', labelsize=12)\n    ax.tick_params(axis='x', labelsize=10)\n    \n    # Ajout des annotations\n    for i, (index, value) in enumerate(df[label_column].value_counts().items()):\n        ax.text(\n            value + max(df[label_column].value_counts())*0.02,\n            i,\n            f'{value} ({value/len(df):.1%})',\n            va='center',\n            fontsize=11,\n            color='black'\n        )\n    \n    # Titres et labels\n    ax.set_title('Distribution des Catégories de Défauts', pad=20, fontsize=14)\n    ax.set_xlabel('Nombre d\\'occurrences', labelpad=10, fontsize=12)\n    ax.set_ylabel('')\n    \n    plt.tight_layout()\n    plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Graphique representant les distributions du dataset a trois classes**","metadata":{}},{"cell_type":"code","source":"\n\n\nplot_label_distribution(df_label, label_column='label')\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Graphique representant les distributions du dataset a 04 classes (defective )**","metadata":{}},{"cell_type":"code","source":"plot_label_distribution(df_defective, label_column='label')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Fonction qui affiche les valeurs numeriques des proportions de chaques classes**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef show_label_proportions(df, label_column='label'):\n    \"\"\"\n    Affiche et retourne les proportions de chaque catégorie dans la colonne spécifiée.\n    \n    Args:\n        df: DataFrame contenant les données.\n        label_column: Nom de la colonne contenant les labels.\n    \n    Returns:\n        DataFrame avec les catégories, leur count et leur pourcentage.\n    \"\"\"\n    # Compter les occurrences de chaque label\n    label_counts = df[label_column].value_counts()\n    \n    # Calculer les pourcentages\n    total = len(df)\n    proportions = pd.DataFrame({\n        'Label': label_counts.index,\n        'Count': label_counts.values,\n        'Percentage': (label_counts.values / total) * 100\n    })\n\n    # Afficher les résultats\n    print(\"\\nLabel\\t\\tCount\\tPercentage\")\n    for _, row in proportions.iterrows():\n        print(f\"{row['Label']:<12}\\t{int(row['Count'])}\\t{row['Percentage']:.1f}%\")\n\n    return proportions\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Affichage des proportions du dataset a trois classes**","metadata":{}},{"cell_type":"code","source":"show_label_proportions(df_label, \"label\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Ici on parcour le dataframe generale et lorsque on rencontre une image defective ('bruised', 'cracked', 'rotten', 'spotted') on le renomme en defective. Le but est d'avoir un dataset avec trois 03 classes (defective, unripe, unaffected)**","metadata":{}},{"cell_type":"code","source":"def mark_defective_labels(df):\n    \"\"\"\n    Modifie le DataFrame en remplaçant les labels contenant des défauts\n    ('bruised', 'cracked', 'rotten', 'spotted') par 'defective'.\n    \"\"\"\n    df = df.copy()  # Pour ne pas modifier l'original directement\n    defective_keywords = ['bruised', 'cracked', 'rotten', 'spotted']\n\n    df['label'] = df['label'].apply(\n        lambda x: 'defective' if any(keyword in x.lower() for keyword in defective_keywords) else x\n    )\n\n    return df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Reduissons le pourcentage defective pour qu'il ne soit plus trop majoritaire et qui ne biaise pas les donnees**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndef reduire_instance(df, nom_instance, pourcentage_reduction):\n    \"\"\"\n    Réduit le nombre d'instances d'une catégorie spécifique dans un DataFrame.\n    \n    Args:\n        df (pd.DataFrame): DataFrame contenant les données\n        nom_instance (str): Nom de la catégorie à réduire (ex: 'bruised')\n        pourcentage_reduction (float): Pourcentage de réduction (0-100)\n    \n    Returns:\n        pd.DataFrame: DataFrame avec le nombre d'instances réduit\n    \"\"\"\n    # Vérification des entrées\n    if pourcentage_reduction < 0 or pourcentage_reduction > 100:\n        raise ValueError(\"Le pourcentage doit être entre 0 et 100\")\n    \n    # Séparation des instances cibles et autres\n    mask = df['label'].str.startswith(nom_instance)\n    instances_cibles = df[mask]\n    autres_instances = df[~mask]\n    \n    # Calcul du nouveau nombre d'instances\n    n_original = len(instances_cibles)\n    n_conserver = int(n_original * (100 - pourcentage_reduction) / 100)\n    \n    # Échantillonnage aléatoire\n    instances_reduites = instances_cibles.sample(n=n_conserver, random_state=42)\n    \n    # Reconstitution du DataFrame\n    df_reduit = pd.concat([autres_instances, instances_reduites])\n    \n    # Information sur la réduction\n    print(f\"Réduction de {nom_instance}:\")\n    print(f\"- Avant: {n_original} instances\")\n    print(f\"- Après: {n_conserver} instances ({pourcentage_reduction}% de réduction)\")\n    print(f\"- Total dataframe: {len(df_reduit)} instances (initial: {len(df)})\")\n    \n    return df_reduit.reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Reduisons 70% des donnees pour que la distribution soit equilibre**","metadata":{}},{"cell_type":"code","source":"# Réduire de 70% les instances 'bruised'\ndf_label_reduit = reduire_instance(df_label, 'defective', 70)\nshow_label_proportions(df_label_reduit, \"label\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_label_reduit.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Classe de la pipeline d'entrainement**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom PIL import Image\nimport pandas as pd\nfrom typing import Dict, Optional\nfrom IPython.display import clear_output, display\nimport time\n\n# Classe LiveMetricsTracker (inchangée)\nclass LiveMetricsTracker:\n    \"\"\"Classe pour afficher les métriques en temps réel\"\"\"\n    def __init__(self):\n        self.fig, (self.ax1, self.ax2, self.ax3) = plt.subplots(1, 3, figsize=(18, 5))\n        self.fig.canvas.header_visible = False\n        plt.ion()\n        self.show()\n    \n    def update(self, history, current_epoch, total_epochs):\n        \"\"\"Met à jour les graphiques\"\"\"\n        clear_output(wait=True)\n        \n        self.ax1.clear()\n        self.ax1.plot(history['train_loss'], label='Train')\n        self.ax1.plot(history['val_loss'], label='Validation')\n        self.ax1.set_title(f'Loss (Epoch {current_epoch}/{total_epochs})')\n        self.ax1.set_xlabel('Epoch')\n        self.ax1.set_ylabel('Loss')\n        self.ax1.legend()\n        \n        self.ax2.clear()\n        self.ax2.plot(history['train_acc'], label='Train')\n        self.ax2.plot(history['val_acc'], label='Validation')\n        self.ax2.set_title(f'Accuracy (Best: {max(history[\"val_acc\"]):.2f}%)')\n        self.ax2.set_xlabel('Epoch')\n        self.ax2.set_ylabel('Accuracy (%)')\n        self.ax2.legend()\n        \n        self.ax3.clear()\n        self.ax3.plot(history['lr_body'], label='Body LR')\n        self.ax3.plot(history['lr_head'], label='Head LR')\n        self.ax3.set_title('Learning Rates')\n        self.ax3.set_xlabel('Epoch')\n        self.ax3.set_ylabel('LR')\n        self.ax3.set_yscale('log')\n        self.ax3.legend()\n        \n        plt.tight_layout()\n        self.show()\n        time.sleep(0.1)\n    \n    def show(self):\n        \"\"\"Affiche le graphique\"\"\"\n        display(self.fig)\n        plt.close()\n\n# Classe PlumImageDataset (inchangée)\nclass PlumImageDataset(Dataset):\n    \"\"\"Dataset personnalisé pour les DataFrames de prunes\"\"\"\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n        self.classes = sorted(df['classes'].unique())\n        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_array = self.df.iloc[idx]['image']\n        label = self.df.iloc[idx]['classes']\n        \n        img = Image.fromarray(img_array.astype('uint8'))\n        \n        if self.transform:\n            img = self.transform(img)\n            \n        return img, self.class_to_idx[label]\n\n# Classe AdvancedPlumTrainer (corrigée)\nclass AdvancedPlumTrainer:\n    def __init__(self, hyperparams: Dict, train_df: pd.DataFrame, model_name: str = 'convnext_large', val_split: float = 0.2):\n        self.hp = hyperparams\n        self.train_df = train_df\n        self.model_name = model_name\n        self.val_split = val_split\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.metrics_tracker = LiveMetricsTracker()\n        \n        # Division des données en train et validation\n        train_idx, val_idx = train_test_split(\n            range(len(train_df)),\n            test_size=self.val_split,\n            stratify=train_df['classes'],\n            random_state=42\n        )\n        train_subset = train_df.iloc[train_idx].reset_index(drop=True)\n        val_subset = train_df.iloc[val_idx].reset_index(drop=True)\n        \n        # Initialisation des datasets et loaders\n        self.train_dataset = PlumImageDataset(train_subset, self.get_train_transform())\n        self.val_dataset = PlumImageDataset(val_subset, self.get_test_transform())\n        \n        self.train_loader = DataLoader(self.train_dataset, \n                                     batch_size=self.hp['batch_size'], \n                                     shuffle=True,\n                                     num_workers=2)\n        self.val_loader = DataLoader(self.val_dataset, \n                                   batch_size=self.hp['batch_size'],\n                                   num_workers=2)\n        \n        # Initialisation du modèle\n        self.initialize_model()\n        \n        # Initialisation de l'optimiseur et du scheduler\n        self.initialize_optimizer()\n        self.criterion = nn.CrossEntropyLoss()\n        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            self.optimizer, \n            'min', \n            patience=self.hp['scheduler_patience'], \n            factor=self.hp['scheduler_factor']\n        )\n    \n    def get_train_transform(self):\n        return transforms.Compose([\n            transforms.Resize((self.hp['resize_size'], self.hp['resize_size'])),\n            transforms.RandomResizedCrop(self.hp['crop_size']),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(15),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    \n    def get_test_transform(self):\n        return transforms.Compose([\n            transforms.Resize((self.hp['resize_size'], self.hp['resize_size'])),\n            transforms.CenterCrop(self.hp['crop_size']),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    \n    def initialize_model(self):\n        \"\"\"Initialise le modèle avec les hyperparamètres\"\"\"\n        model_fn = getattr(models, self.model_name)\n        self.model = model_fn(weights='IMAGENET1K_V1')  # Charger les poids pré-entraînés\n        \n        # Geler toutes les couches initialement\n        for param in self.model.parameters():\n            param.requires_grad = False\n        \n        # Modifier la couche classifier pour ConvNeXt\n        if 'convnext' in self.model_name:\n            in_features = self.model.classifier[-1].in_features\n            num_classes = len(self.train_dataset.classes)\n            self.model.classifier[-1] = nn.Linear(in_features, num_classes)\n            # Activer requires_grad pour la nouvelle couche\n            for param in self.model.classifier[-1].parameters():\n                param.requires_grad = True\n        \n        self.model = self.model.to(self.device)\n    \n    def unfreeze_layers(self):\n        \"\"\"Dégèle un pourcentage des couches du modèle\"\"\"\n        all_params = list(self.model.parameters())\n        num_params = len(all_params)\n        num_to_unfreeze = int(self.hp['unfreeze_ratio'] * num_params)\n        \n        # Dégeler les dernières couches (excluant le classifier)\n        for param in all_params[-num_to_unfreeze:]:\n            param.requires_grad = True\n        \n        # Mettre à jour l'optimiseur pour inclure les nouveaux paramètres dégélés\n        self.initialize_optimizer()\n    \n    def initialize_optimizer(self):\n        \"\"\"Initialise l'optimiseur avec deux groupes de paramètres (body et head)\"\"\"\n        # Paramètres de la tête (classifier)\n        head_params = list(self.model.classifier[-1].parameters())\n        # Paramètres du corps (tous sauf le classifier)\n        body_params = [p for p in self.model.parameters() if id(p) not in [id(hp) for hp in head_params] and p.requires_grad]\n        \n        if self.hp['optimizer'].lower() == 'adamw':\n            self.optimizer = optim.AdamW([\n                {'params': body_params, 'lr': self.hp['lr_body'], 'weight_decay': self.hp['wd_body']},\n                {'params': head_params, 'lr': self.hp['lr_head'], 'weight_decay': self.hp['wd_head']}\n            ])\n        else:\n            self.optimizer = optim.SGD([\n                {'params': body_params, 'lr': self.hp['lr_body'], 'weight_decay': self.hp['wd_body']},\n                {'params': head_params, 'lr': self.hp['lr_head'], 'weight_decay': self.hp['wd_head']}\n            ], momentum=self.hp['momentum'])\n    \n    def train(self) -> nn.Module:\n        \"\"\"Entraîne le modèle avec visualisation en temps réel\"\"\"\n        self.history = {\n            'train_loss': [], 'train_acc': [],\n            'val_loss': [], 'val_acc': [],\n            'lr_body': [], 'lr_head': []\n        }\n        \n        best_val_acc = 0.0\n        \n        for epoch in range(self.hp['num_epochs']):\n            # Dégeler les couches après freeze_epochs\n            if epoch == self.hp['freeze_epochs']:\n                self.unfreeze_layers()\n            \n            # Phase d'entraînement\n            self.model.train()\n            running_loss = 0.0\n            correct = 0\n            total = 0\n            \n            for inputs, labels in tqdm(self.train_loader, desc=f'Epoch {epoch+1}'):\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\n                \n                self.optimizer.zero_grad()\n                outputs = self.model(inputs)\n                loss = self.criterion(outputs, labels)\n                loss.backward()\n                self.optimizer.step()\n                \n                running_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n            \n            train_loss = running_loss / total\n            train_acc = 100. * correct / total\n            \n            # Phase de validation\n            val_loss, val_acc = self.evaluate(self.val_loader)\n            self.scheduler.step(val_loss)\n            \n            # Mise à jour des métriques\n            self.history['train_loss'].append(train_loss)\n            self.history['train_acc'].append(train_acc)\n            self.history['val_loss'].append(val_loss)\n            self.history['val_acc'].append(val_acc)\n            self.history['lr_body'].append(self.optimizer.param_groups[0]['lr'])\n            self.history['lr_head'].append(self.optimizer.param_groups[1]['lr'])\n            \n            # Affichage console\n            print(f'\\nEpoch {epoch+1:03d}/{self.hp[\"num_epochs\"]}')\n            print(f'{\"Train\":<10} Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%')\n            print(f'{\"Val\":<10} Loss: {val_loss:.4f} | Acc: {val_acc:.2f}%')\n            print(f'{\"LR\":<10} Body: {self.history[\"lr_body\"][-1]:.2e} | Head: {self.history[\"lr_head\"][-1]:.2e}')\n            \n            # Mise à jour des graphiques\n            self.metrics_tracker.update(self.history, epoch+1, self.hp['num_epochs'])\n            \n            # Sauvegarde du meilleur modèle\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                self.save_checkpoint(epoch, val_acc)\n                print(f'New best model saved (Acc: {val_acc:.2f}%)')\n        \n        # Charger le meilleur modèle avant de le retourner\n        checkpoint = torch.load('best_model.pth')\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        \n        return self.model\n    \n    def evaluate(self, loader):\n        \"\"\"Évaluation du modèle\"\"\"\n        self.model.eval()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for inputs, labels in loader:\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\n                outputs = self.model(inputs)\n                loss = self.criterion(outputs, labels)\n                \n                running_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        return running_loss / total, 100. * correct / total\n    \n    def save_checkpoint(self, epoch, val_acc):\n        \"\"\"Sauvegarde le modèle\"\"\"\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'val_acc': val_acc,\n        }, 'best_model.pth')\n    \n    def plot_results(self):\n        \"\"\"Visualisation des résultats finaux\"\"\"\n        plt.figure(figsize=(15, 5))\n        \n        plt.subplot(1, 3, 1)\n        plt.plot(self.history['train_loss'], label='Train')\n        plt.plot(self.history['val_loss'], label='Validation')\n        plt.title('Training and Validation Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        \n        plt.subplot(1, 3, 2)\n        plt.plot(self.history['train_acc'], label='Train')\n        plt.plot(self.history['val_acc'], label='Validation')\n        plt.title('Training and Validation Accuracy')\n        plt.xlabel('Epoch')\n        plt.ylabel('Accuracy (%)')\n        plt.legend()\n        \n        plt.subplot(1, 3, 3)\n        plt.plot(self.history['lr_body'], label='Body LR')\n        plt.plot(self.history['lr_head'], label='Head LR')\n        plt.title('Learning Rate Evolution')\n        plt.xlabel('Epoch')\n        plt.ylabel('LR')\n        plt.yscale('log')\n        plt.legend()\n        \n        plt.tight_layout()\n        plt.show()\n\n    def evaluate_test_data(self, test_df, model=None):\n        \"\"\"\n        Évalue les performances du modèle sur les données de test\n        \n        Args:\n            test_df (pd.DataFrame): DataFrame contenant les images de test et leurs classes\n            model (nn.Module, optional): Modèle à évaluer. Si None, utilise self.model\n        \n        Returns:\n            dict: Dictionnaire contenant les métriques d'évaluation (accuracy, loss, confusion matrix, etc.)\n        \"\"\"\n        if model is None:\n            model = self.model\n        \n        # Créer le dataset et dataloader de test\n        test_dataset = PlumImageDataset(test_df, self.get_test_transform())\n        test_loader = DataLoader(\n            test_dataset, \n            batch_size=self.hp['batch_size'],\n            num_workers=2\n        )\n        \n        # Mettre le modèle en mode évaluation\n        model.eval()\n        \n        # Initialiser les variables pour le suivi\n        test_loss = 0.0\n        correct = 0\n        total = 0\n        \n        # Préparer les tableaux pour la matrice de confusion\n        all_preds = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for inputs, labels in tqdm(test_loader, desc=\"Évaluation sur test\"):\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\n                \n                # Faire la prédiction\n                outputs = model(inputs)\n                loss = self.criterion(outputs, labels)\n                \n                # Calculer les métriques\n                test_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                \n                # Stocker pour la matrice de confusion\n                all_preds.extend(predicted.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n        \n        # Calculer les métriques finales\n        accuracy = 100. * correct / total\n        avg_loss = test_loss / total\n        \n        # Calculer la matrice de confusion\n        from sklearn.metrics import confusion_matrix, classification_report\n        conf_matrix = confusion_matrix(all_labels, all_preds)\n        class_report = classification_report(all_labels, all_preds, \n                                             target_names=test_dataset.classes,\n                                             output_dict=True)\n        \n        # Afficher les résultats\n        print(f\"\\nRésultats sur le jeu de test:\")\n        print(f\"Accuracy: {accuracy:.2f}%\")\n        print(f\"Loss: {avg_loss:.4f}\")\n        \n        # Visualiser la matrice de confusion\n        plt.figure(figsize=(10, 8))\n        plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n        plt.title('Matrice de confusion')\n        plt.colorbar()\n        \n        # Étiquettes pour la matrice de confusion\n        tick_marks = np.arange(len(test_dataset.classes))\n        plt.xticks(tick_marks, test_dataset.classes, rotation=45)\n        plt.yticks(tick_marks, test_dataset.classes)\n        \n        # Afficher les valeurs dans la matrice\n        thresh = conf_matrix.max() / 2.\n        for i in range(conf_matrix.shape[0]):\n            for j in range(conf_matrix.shape[1]):\n                plt.text(j, i, format(conf_matrix[i, j], 'd'),\n                         ha=\"center\", va=\"center\",\n                         color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n        \n        plt.tight_layout()\n        plt.ylabel('Vraie classe')\n        plt.xlabel('Classe prédite')\n        plt.show()\n        \n        # Créer et retourner un dictionnaire avec toutes les métriques\n        results = {\n            'accuracy': accuracy,\n            'loss': avg_loss,\n            'confusion_matrix': conf_matrix,\n            'classification_report': class_report,\n            'predictions': all_preds,\n            'true_labels': all_labels\n        }\n        \n        return results\n\n# # Exemple d'utilisation\n# if __name__ == \"__main__\":\n#     HYPERPARAMS = {\n#         'model_name': 'convnext_large',\n#         'batch_size': 32,\n#         'num_epochs': 50,\n#         'freeze_epochs': 5,\n#         'unfreeze_ratio': 0.5,\n#         'optimizer': 'adamw',\n#         'lr_body': 1e-5,\n#         'lr_head': 1e-4,\n#         'wd_body': 0.01,\n#         'wd_head': 0.001,\n#         'momentum': 0.9,\n#         'weight_decay': 1e-4,\n#         'resize_size': 256,\n#         'crop_size': 224,\n#         'scheduler_patience': 3,\n#         'scheduler_factor': 0.1\n#     }\n    \n#     # Supposons que train_data_03_classes est un DataFrame pandas avec les colonnes 'image' et 'classes'\n#     trainer = AdvancedPlumTrainer(HYPERPARAMS, train_data_03_classes, model_name='convnext_large')\n#     model1 = trainer.train()\n#     trainer.plot_results()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_03_classes = df_label_reduit\ntrain_data_03_classes = train_data_03_classes.rename(columns={'label': 'classes'})\n\ntrain_data_04_classes_defective = df_defective\ntrain_data_04_classes_defective = train_data_04_classes_defective.rename(columns={'label': 'classes'})\n\ntest_data = df_test\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Definition des hyper parametres et execution du modele1**","metadata":{}},{"cell_type":"code","source":" HYPERPARAMS = {\n    'model_name': 'convnext_large',\n    'batch_size': 32,\n    'num_epochs': 50,\n    'freeze_epochs': 5,\n    'unfreeze_ratio': 0.5,\n    'optimizer': 'adamw',\n    'lr_body': 1e-5,\n    'lr_head': 1e-4,\n    'wd_body': 0.01,\n    'wd_head': 0.001,\n    'momentum': 0.9,\n    'weight_decay': 1e-4,\n    'resize_size': 256,\n    'crop_size': 224,\n    'scheduler_patience': 3,\n    'scheduler_factor': 0.1\n}\n\n# Supposons que train_data_03_classes est un DataFrame pandas avec les colonnes 'image' et 'classes'\ntrainer = AdvancedPlumTrainer(HYPERPARAMS, train_data_03_classes, model_name='convnext_large')\nmodel1 = trainer.train()\ntrainer.plot_results()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Definition des hyper parametres et execution du modele1**","metadata":{}},{"cell_type":"code","source":" HYPERPARAMS = {\n    'model_name': 'convnext_large',\n    'batch_size': 32,\n    'num_epochs': 30,\n    'freeze_epochs': 5,\n    'unfreeze_ratio': 0.5,\n    'optimizer': 'adamw',\n    'lr_body': 1e-5,\n    'lr_head': 1e-4,\n    'wd_body': 0.01,\n    'wd_head': 0.001,\n    'momentum': 0.9,\n    'weight_decay': 1e-4,\n    'resize_size': 256,\n    'crop_size': 224,\n    'scheduler_patience': 3,\n    'scheduler_factor': 0.1\n}\n\n# Supposons que train_data_03_classes est un DataFrame pandas avec les colonnes 'image' et 'classes'\ntrainer2 = AdvancedPlumTrainer(HYPERPARAMS, train_data_04_classes_defective, model_name='convnext_large')\nmodel2 = trainer2.train()\ntrainer2.plot_results()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Sauvegarde des modeles**","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Sauvegarde complète (poids + métriques + infos d'entraînement)\ntorch.save({\n    # 'epoch': epoch,\n    'model_state_dict': model1.state_dict(),  # Poids du modèle\n    # 'optimizer_state_dict': optimizer.state_dict(),\n    # 'loss': train_loss,\n    # 'accuracy': val_accuracy,\n    # 'best_accuracy': best_accuracy,\n}, 'resnet_model1.pth')  # Extension .pth ou .pt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Sauvegarde complète (poids + métriques + infos d'entraînement)\ntorch.save({\n    # 'epoch': epoch,\n    'model_state_dict': model2.state_dict(),  # Poids du modèle\n    # 'optimizer_state_dict': optimizer.state_dict(),\n    # 'loss': train_loss,\n    # 'accuracy': val_accuracy,\n    # 'best_accuracy': best_accuracy,\n}, 'resnet_model2.pth')  # Extension .pth ou .pt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Fusion des deux modeles en un seule modele**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom PIL import Image\n\nclass CombinedModel(nn.Module):\n    def __init__(self, model1, model2, test_transform=None):\n        super().__init__()\n        self.model1 = model1\n        self.model2 = model2\n        self.test_transform = test_transform\n        \n        # Mapping index -> label pour clarté\n        self.model1_classes = ['defective', 'unaffected', 'unripe']\n        self.model2_classes = ['bruised', 'cracked', 'rotten', 'spotted']\n        self.final_classes = ['bruised', 'cracked', 'rotten', 'spotted', 'unaffected', 'unripe']\n        \n        # Mettre les modèles en mode évaluation\n        self.model1.eval()\n        self.model2.eval()\n    \n    def preprocess_image(self, image):\n        \"\"\"Prétraite une image avant de la passer aux modèles\"\"\"\n        # Si c'est un tableau numpy, convertir en PIL Image\n        if isinstance(image, np.ndarray):\n            image = Image.fromarray(image.astype('uint8'))\n        \n        # Appliquer les transformations si disponibles\n        if self.test_transform:\n            return self.test_transform(image).unsqueeze(0)  # Ajouter dimension batch\n        else:\n            # Transformations par défaut si aucune n'est fournie\n            transform = transforms.Compose([\n                transforms.Resize((224, 224)),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n            ])\n            return transform(image).unsqueeze(0)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass du modèle combiné\n        \n        Args:\n            x: Peut être une image PIL, un tableau numpy, ou un tensor PyTorch\n            \n        Returns:\n            dict: Dictionnaire contenant les prédictions et probabilités\n        \"\"\"\n        # Vérifier si x est déjà un tensor PyTorch\n        if not isinstance(x, torch.Tensor):\n            x = self.preprocess_image(x)\n        \n        # S'assurer que le tensor est sur le bon device\n        device = next(self.model1.parameters()).device\n        x = x.to(device)\n        \n        # Passage à travers le modèle 1 pour la classification initiale\n        with torch.no_grad():\n            out1 = self.model1(x)\n            probas1 = torch.softmax(out1, dim=1)\n            pred1 = torch.argmax(probas1, dim=1)\n            \n            batch_size = x.size(0)\n            final_preds = []\n            final_probas = []\n            \n            for i in range(batch_size):\n                # Prédiction du modèle 1 pour cette image\n                class1 = self.model1_classes[pred1[i]]\n                \n                if class1 == 'defective':\n                    # Si défectueux, utiliser le modèle 2 pour déterminer le type de défaut\n                    out2 = self.model2(x[i].unsqueeze(0))\n                    probas2 = torch.softmax(out2, dim=1)\n                    pred2 = torch.argmax(probas2, dim=1).item()\n                    \n                    # Classe finale et probabilité\n                    final_class = self.model2_classes[pred2]\n                    final_proba = probas2[0, pred2].item() * probas1[i, pred1[i]].item()  # Probabilité conjointe\n                else:\n                    # Si non défectueux ou non mûr, utiliser la classification du modèle 1\n                    final_class = class1\n                    final_proba = probas1[i, pred1[i]].item()\n                \n                # Convertir la classe en index dans final_classes\n                final_idx = self.final_classes.index(final_class)\n                \n                final_preds.append(final_idx)\n                final_probas.append(final_proba)\n            \n            # Convertir les listes en tensors\n            final_preds = torch.tensor(final_preds, device=device)\n            final_probas = torch.tensor(final_probas, device=device)\n            \n            return {\n                'pred_idx': final_preds,                   # Indices des classes prédites\n                'pred_class': [self.final_classes[idx] for idx in final_preds],  # Noms des classes prédites\n                'probability': final_probas               # Probabilités des prédictions\n            }\n\n\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Fonction pour evaluer notre modele generale sur les donnees de teste**","metadata":{}},{"cell_type":"code","source":"def evaluate_combined_model(combined_model, test_df, test_transform=None, device='cuda'):\n    \"\"\"\n    Évalue le modèle combiné sur un jeu de données de test\n    \n    Args:\n        combined_model: Le modèle combiné\n        test_df: DataFrame contenant les images et classes de test\n        test_transform: Transformations à appliquer aux images (optionnel)\n        device: Périphérique pour l'inférence ('cuda' ou 'cpu')\n        \n    Returns:\n        dict: Dictionnaire contenant les résultats d'évaluation\n    \"\"\"\n    # Vérifier si CUDA est disponible et respecter le choix de device\n    if device == 'cuda' and not torch.cuda.is_available():\n        print(\"CUDA non disponible, utilisation du CPU à la place\")\n        device = 'cpu'\n    \n    # S'assurer que le modèle est sur le bon device\n    combined_model = combined_model.to(device)\n    \n    # Définir les transformations si non fournies\n    if test_transform is None and combined_model.test_transform is None:\n        test_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n        combined_model.test_transform = test_transform\n    \n    # Initialiser les listes pour stocker les résultats\n    y_true = []\n    y_pred = []\n    y_proba = []\n    \n    # Parcourir le DataFrame de test\n    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Évaluation\"):\n        # Obtenir l'image et la classe réelle\n        image = row['image']\n        true_label = row['classes']\n        \n        # Obtenir l'index de la classe réelle\n        if true_label in combined_model.final_classes:\n            true_idx = combined_model.final_classes.index(true_label)\n        else:\n            print(f\"Attention: classe '{true_label}' non trouvée dans final_classes. Vérifiez vos données.\")\n            continue\n        \n        # Faire une prédiction avec le modèle combiné\n        with torch.no_grad():\n            result = combined_model(image)\n        \n        # Ajouter les résultats aux listes\n        y_true.append(true_idx)\n        y_pred.append(result['pred_idx'].item())\n        y_proba.append(result['probability'].item())\n    \n    # Convertir les listes en tableaux numpy pour l'analyse\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    y_proba = np.array(y_proba)\n    \n    # Convertir les indices en noms de classe\n    class_names = [combined_model.final_classes[idx] for idx in range(len(combined_model.final_classes))]\n    y_true_names = [combined_model.final_classes[idx] for idx in y_true]\n    y_pred_names = [combined_model.final_classes[idx] for idx in y_pred]\n    \n    # Calculer les métriques\n    print(\"\\nRésultats d'évaluation:\")\n    print(f\"Accuracy: {100 * np.mean(y_true == y_pred):.2f}%\")\n    \n    # Rapport de classification\n    print(\"\\nClassification Report:\")\n    cl_report = classification_report(y_true, y_pred, \n                                      target_names=class_names,\n                                      labels=range(len(class_names)),\n                                      output_dict=True)\n    cl_report_df = pd.DataFrame(cl_report).transpose()\n    print(cl_report_df)\n    \n    # Matrice de confusion\n    conf_matrix = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n    conf_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n    print(\"\\nConfusion Matrix:\")\n    print(conf_df)\n    \n    # Visualiser la matrice de confusion\n    plt.figure(figsize=(10, 8))\n    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Matrice de confusion')\n    plt.colorbar()\n    \n    # Étiquettes pour les axes\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names, rotation=45)\n    plt.yticks(tick_marks, class_names)\n    \n    # Afficher les valeurs dans la matrice\n    thresh = conf_matrix.max() / 2.\n    for i in range(conf_matrix.shape[0]):\n        for j in range(conf_matrix.shape[1]):\n            plt.text(j, i, format(conf_matrix[i, j], 'd'),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n    \n    plt.tight_layout()\n    plt.ylabel('Vraie classe')\n    plt.xlabel('Classe prédite')\n    plt.show()\n    \n    # Retourner un dictionnaire avec tous les résultats\n    return {\n        'y_true': y_true,\n        'y_pred': y_pred,\n        'y_proba': y_proba,\n        'y_true_names': y_true_names,\n        'y_pred_names': y_pred_names,\n        'class_names': class_names,\n        'accuracy': np.mean(y_true == y_pred),\n        'classification_report': cl_report,\n        'confusion_matrix': conf_matrix\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ncombined = CombinedModel(model1, model2)\n\n# Définir les transformations pour le test\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Évaluer le modèle combiné\nresults = evaluate_combined_model(combined, test_df, test_transform, device='cuda')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Accuracy: {results['accuracy']:.4f}\")\n\n# Examiner les résultats par classe\nfor class_name in results['class_names']:\n    idx = results['class_names'].index(class_name)\n    correct = np.sum((results['y_true'] == idx) & (results['y_pred'] == idx))\n    total = np.sum(results['y_true'] == idx)\n    print(f\"{class_name}: {correct}/{total} = {correct/total:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}